{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xXM7DoPpds1"
      },
      "source": [
        "## Import deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W24EKFXaO5yC",
        "outputId": "f1a797d5-5b3d-4b1a-9188-cc6a924bea1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting mlable\n",
            "  Downloading mlable-0.8.6-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting tokun\n",
            "  Downloading tokun-0.13.5-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting revml\n",
            "  Downloading revml-0.6.8-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: tensorflow>=2.15 in /usr/local/lib/python3.10/dist-packages (from mlable) (2.15.0)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
            "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m709.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (1.66.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.15->mlable) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.15->mlable) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.15->mlable) (3.2.2)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlable-0.8.6-py3-none-any.whl (23 kB)\n",
            "Downloading tokun-0.13.5-py3-none-any.whl (12 kB)\n",
            "Downloading revml-0.6.8-py3-none-any.whl (7.2 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
            "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m446.8/446.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, multidict, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets, mlable, tokun, revml\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.9.0\n",
            "    Uninstalling fsspec-2024.9.0:\n",
            "      Successfully uninstalled fsspec-2024.9.0\n",
            "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-3.0.0 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.6.1 mlable-0.8.6 multidict-6.1.0 multiprocess-0.70.16 revml-0.6.8 tokun-0.13.5 xxhash-3.5.0 yarl-1.11.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U datasets mlable tokun revml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VXU-Ebl2pddk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e37cefdb-5919-49f0-e461-f90f4ee7bdf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7bec67973eb0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 98, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import functools\n",
        "import itertools\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import urllib.request\n",
        "\n",
        "import datasets as hd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import mlable.data\n",
        "import mlable.metrics\n",
        "import mlable.shaping\n",
        "\n",
        "import revml.contract.model\n",
        "import revml.contract.pipeline\n",
        "\n",
        "import tokun.data\n",
        "import tokun.evaluation\n",
        "import tokun.meta\n",
        "import tokun.model\n",
        "import tokun.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn1ywhSrpin9",
        "outputId": "06a6f335-c412-49c7-cf61-f849e51d14e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.15.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Tensorflow version \" + tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Setup the GPU / TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AWMvVNSAJK_n"
      },
      "outputs": [],
      "source": [
        "# MIXED PRECISION #############################################################\n",
        "\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "vFIMfPmgQa0h",
        "outputId": "149b6547-24c8-48a8-9891-c06c2ec4d75c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a3e0eb4742cb>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mRESOLVER\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_connect_to_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESOLVER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESOLVER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mDISTRIBUTION_STRATEGY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESOLVER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mGPU\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py\u001b[0m in \u001b[0;36minitialize_tpu_system\u001b[0;34m(cluster_resolver)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mno\u001b[0m \u001b[0mTPU\u001b[0m \u001b[0mdevices\u001b[0m \u001b[0mfound\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meager\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m   return tpu_strategy_util.initialize_tpu_system_impl(\n\u001b[0m\u001b[1;32m     73\u001b[0m       cluster_resolver, TPUClusterResolver)\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py\u001b[0m in \u001b[0;36minitialize_tpu_system_impl\u001b[0;34m(cluster_resolver, tpu_cluster_resolver_cls)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu_system_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tpu_init_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m           )\n\u001b[1;32m    917\u001b[0m       )\n\u001b[0;32m--> 918\u001b[0;31m       return self._concrete_variable_creation_fn._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    919\u001b[0m           \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_variable_creation_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# DEVICES #####################################################################\n",
        "\n",
        "tf.debugging.set_log_device_placement(False)\n",
        "\n",
        "CPU = tf.config.list_logical_devices('CPU')\n",
        "GPU = tf.config.list_logical_devices('GPU')\n",
        "TPU = tf.config.list_logical_devices('TPU')\n",
        "\n",
        "if TPU:\n",
        "    RESOLVER = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(RESOLVER)\n",
        "    tf.tpu.experimental.initialize_tpu_system(RESOLVER)\n",
        "    DISTRIBUTION_STRATEGY = tf.distribute.TPUStrategy(RESOLVER)\n",
        "elif GPU:\n",
        "    DISTRIBUTION_STRATEGY = tf.distribute.MirroredStrategy(GPU)\n",
        "else:\n",
        "    DISTRIBUTION_STRATEGY = tf.distribute.MirroredStrategy(CPU)\n",
        "\n",
        "print(DISTRIBUTION_STRATEGY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9066X5EOyAX"
      },
      "source": [
        "## Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFSPMtQaO1fu"
      },
      "outputs": [],
      "source": [
        "# TOGGLE ######################################################################\n",
        "\n",
        "IMPORT = False\n",
        "DOWNLOAD = False\n",
        "TRAINING = True\n",
        "BINARY = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t1jfsJlM3SX"
      },
      "source": [
        "## Defining The Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAcVbS3_4jov"
      },
      "outputs": [],
      "source": [
        "# DATA PARAMETERS #############################################################\n",
        "\n",
        "BATCH_CONFIG = {\n",
        "    'batch_size': 64,\n",
        "    'drop_remainder': True,\n",
        "    'num_parallel_calls': tf.data.AUTOTUNE,}\n",
        "\n",
        "PIPELINE_CONFIG = {\n",
        "    'encoder': {\n",
        "        'batch_dim': BATCH_CONFIG['batch_size'],\n",
        "        'sample_dim': 512 * 8 * 33, # in bytes != codepoints\n",
        "        'input_dim': 8 * 33,\n",
        "        'sequence_axis': 1,\n",
        "        'feature_axis': -1,},\n",
        "    'decoder': {\n",
        "        'batch_dim': BATCH_CONFIG['batch_size'],\n",
        "        'sample_dim': 512 * 2 * 33,\n",
        "        'input_dim': 2 * 33,\n",
        "        'sequence_axis': 1,\n",
        "        'feature_axis': -1,\n",
        "        'data_weight': 1.0,\n",
        "        'padding_weight': 0.01,}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z74MlibMWnu"
      },
      "outputs": [],
      "source": [
        "# DECODER PARAMETERS ##########################################################\n",
        "\n",
        "DECODER_CONFIG = {\n",
        "  'num_layers': 8,\n",
        "  'num_heads': 16,\n",
        "  'input_dim': PIPELINE_CONFIG['decoder']['input_dim'],\n",
        "  'context_dim': PIPELINE_CONFIG['encoder']['input_dim'],\n",
        "  'embed_dim': 1056, # 4 * 33 * 8\n",
        "  'head_dim': 1056 // 16,\n",
        "  'hidden_dim': 1056 * 4,\n",
        "  'epsilon': 1e-6,}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm6y63XRBz07"
      },
      "outputs": [],
      "source": [
        "# DERIVED DECODING PARAMETERS #################################################\n",
        "\n",
        "DECODER_META = {\n",
        "    'version': '0.1',\n",
        "    'path': 'decoder.keras',\n",
        "    'url': '',}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21J7WEkhSwph"
      },
      "outputs": [],
      "source": [
        "# TRAINING PARAMETERS #########################################################\n",
        "\n",
        "OPTIMIZER_CONFIG = {\n",
        "    'learning_rate': 4 * 0.001 * (0.1 if IMPORT else 1.0),\n",
        "    'weight_decay': 0.1,\n",
        "    'beta_1': 0.9,\n",
        "    'beta_2': 0.95,\n",
        "    'clipnorm': 1.0,}\n",
        "\n",
        "SCHEDULER_CONFIG = {\n",
        "    'initial_learning_rate': OPTIMIZER_CONFIG['learning_rate'],\n",
        "    'decay_steps': 800 * 3,\n",
        "    'alpha': 0.1,\n",
        "    'name': 'cosine_lr',\n",
        "    'warmup_target': None,\n",
        "    'warmup_steps': 0,}\n",
        "\n",
        "METRICS_CONFIG = {\n",
        "    # 'factor': 256,\n",
        "    'depth': 8,}\n",
        "\n",
        "LOSS_CONFIG = {\n",
        "    'from_logits': False,\n",
        "    'label_smoothing': 0.,\n",
        "    'axis': -1,\n",
        "    'reduction': 'sum_over_batch_size',\n",
        "    'name': 'loss',}\n",
        "\n",
        "CHECKPOINT_CONFIG = {\n",
        "    'filepath': DECODER_META['path'],\n",
        "    'monitor': 'val_loss',\n",
        "    'mode': 'auto',\n",
        "    'save_freq': 'epoch',\n",
        "    'save_best_only': False,\n",
        "    'save_weights_only': False,\n",
        "    'verbose': 1,}\n",
        "\n",
        "TENSORBOARD_CONFIG = {\n",
        "    'log_dir': os.path.join('.logs/', *DECODER_META['version'], datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
        "    'histogram_freq': 1,\n",
        "    'embeddings_freq': 0,\n",
        "    'profile_batch': (128, 256),\n",
        "    'write_graph': False,\n",
        "    'write_images': True,}\n",
        "\n",
        "TRAINING_CONFIG = {\n",
        "    'epochs': 8,\n",
        "    'batch_size': None,\n",
        "    'validation_split': None,\n",
        "    'validation_freq': list(range(1, 9)),\n",
        "    # 'class_weight': {__c: 0.03 if __c == 0 else 1. for __c in range(PIPELINE_CONFIG['decoder']['input_dim'])}, # there are 32 times more 0s than other bytes (most instructions have null data)\n",
        "    'verbose': 1,}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zjz1sxOju7jM"
      },
      "source": [
        "## Download The Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfIZb86Fg0dQ"
      },
      "outputs": [],
      "source": [
        "# DECODER #####################################################################\n",
        "\n",
        "if IMPORT and DOWNLOAD:\n",
        "    urllib.request.urlretrieve(DECODER_META['url'], DECODER_META['path'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEyFtkcFNGe4"
      },
      "source": [
        "## Loading The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukG8ql_qxOl_"
      },
      "outputs": [],
      "source": [
        "# EVMC DATASET ################################################################\n",
        "\n",
        "EVMC_TRAIN = hd.load_dataset('apehex/evm_contracts', name='hex-ethereum', split='cleaned[:90%]').to_tf_dataset(shuffle=True, batch_size=None)\n",
        "EVMC_TEST = hd.load_dataset('apehex/evm_contracts', name='hex-ethereum', split='cleaned[90%:]').to_tf_dataset(shuffle=True, batch_size=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cheN52OEchs"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJMB7pPdCcnA"
      },
      "outputs": [],
      "source": [
        "# EVMC ########################################################################\n",
        "\n",
        "# specialized preprocessing fn\n",
        "__preprocess = revml.contract.pipeline.preprocess_factory(\n",
        "    decoder_config=PIPELINE_CONFIG['decoder'],\n",
        "    encoder_config=PIPELINE_CONFIG['encoder'],)\n",
        "\n",
        "# apply\n",
        "with DISTRIBUTION_STRATEGY.scope():\n",
        "    EVMC_TRAIN = EVMC_TRAIN.batch(**BATCH_CONFIG).map(__preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    EVMC_TEST = EVMC_TEST.batch(**BATCH_CONFIG).map(__preprocess, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ3quJQ4EUKf"
      },
      "outputs": [],
      "source": [
        "# INSPECT #####################################################################\n",
        "\n",
        "(__X, __C), __T, __W = next(iter(EVMC_TEST.take(1)))\n",
        "\n",
        "print(EVMC_TRAIN.element_spec)\n",
        "print(EVMC_TEST.element_spec)\n",
        "\n",
        "print('evmc train: {:,}'.format(EVMC_TRAIN.cardinality().numpy()))\n",
        "print('evmc test:  {:,}'.format(EVMC_TEST.cardinality().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbkaXey44V5Q"
      },
      "source": [
        "## Init The Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP_Jj3JYY3yb"
      },
      "outputs": [],
      "source": [
        "# DEBUG #######################################################################\n",
        "\n",
        "class DebugModel(tf.keras.models.Model):\n",
        "    def __init__(self, output_dim: int, **kwargs) -> None:\n",
        "        # init\n",
        "        super(DebugModel, self).__init__(**kwargs)\n",
        "        # layers\n",
        "        self._head = tf.keras.layers.Dense(units=output_dim, activation='sigmoid', use_bias=False, kernel_initializer='glorot_uniform', bias_initializer='zeros', name='head')\n",
        "\n",
        "    def call(self, inputs: tuple, **kwargs) -> tf.Tensor:\n",
        "        return self._head(inputs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqJLSg1atBo7"
      },
      "outputs": [],
      "source": [
        "# METRICS #####################################################################\n",
        "\n",
        "_Accuracy = mlable.metrics.BinaryGroupAccuracy if BINARY else mlable.metrics.RawGroupAccuracy\n",
        "_Loss = tf.keras.losses.BinaryCrossentropy if BINARY else tf.keras.losses.MeanSquaredError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEpY1-vFIFX7"
      },
      "outputs": [],
      "source": [
        "# COMPILE #####################################################################\n",
        "\n",
        "with DISTRIBUTION_STRATEGY.scope():\n",
        "    # COSINE LR ###############################################################\n",
        "    cosine_lr = tf.keras.optimizers.schedules.CosineDecay(**SCHEDULER_CONFIG)\n",
        "    OPTIMIZER_CONFIG['learning_rate'] = cosine_lr\n",
        "    # metrics\n",
        "    byte_accuracy = _Accuracy(group=1, name='byte_accuracy', **METRICS_CONFIG)\n",
        "    instruction_accuracy = _Accuracy(group=33, name='instruction_accuracy', **METRICS_CONFIG)\n",
        "    token_accuracy = _Accuracy(group=DECODER_CONFIG['input_dim'], name='token_accuracy', **METRICS_CONFIG)\n",
        "    # decoder\n",
        "    DECODER = revml.contract.model.Transformer(**DECODER_CONFIG)\n",
        "    if IMPORT and os.path.isfile(DECODER_META['path']): DECODER = tf.keras.models.load_model(DECODER_META['path'], compile=False)\n",
        "    # build\n",
        "    DECODER((__X, __C))\n",
        "    # compile\n",
        "    DECODER.compile(\n",
        "        optimizer=tf.keras.optimizers.AdamW(**OPTIMIZER_CONFIG),\n",
        "        loss=_Loss(**LOSS_CONFIG),\n",
        "        weighted_metrics=[byte_accuracy, instruction_accuracy, token_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuRwWdjpPQBM"
      },
      "outputs": [],
      "source": [
        "DECODER.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRkNkXthBwar"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beTpALmzFdu1"
      },
      "outputs": [],
      "source": [
        "# TRAIN #######################################################################\n",
        "\n",
        "if TRAINING:\n",
        "    with DISTRIBUTION_STRATEGY.scope():\n",
        "        # callbacks\n",
        "        cp_callback = tf.keras.callbacks.ModelCheckpoint(**CHECKPOINT_CONFIG)\n",
        "        tb_callback = tf.keras.callbacks.TensorBoard(**TENSORBOARD_CONFIG)\n",
        "        # fit model\n",
        "        TRAINING_HISTORY = DECODER.fit(\n",
        "            x=EVMC_TRAIN.prefetch(tf.data.AUTOTUNE),\n",
        "            validation_data=EVMC_TEST.prefetch(tf.data.AUTOTUNE),\n",
        "            callbacks=[cp_callback, tb_callback],\n",
        "            **TRAINING_CONFIG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHtROW1K1R7c"
      },
      "source": [
        "## Dataviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiRVgG-oSfb7"
      },
      "outputs": [],
      "source": [
        "# DATA ########################################################################\n",
        "\n",
        "__i = iter(EVMC_TEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DBwlFAb--Ah"
      },
      "outputs": [],
      "source": [
        "(__x, __c), __t, __w = next(__i)\n",
        "__y = DECODER((__x, __c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGuCvlVGN1wg"
      },
      "outputs": [],
      "source": [
        "__s = tf.reshape(__c, (BATCH_CONFIG['batch_size'], -1))\n",
        "__s = tokun.pipeline.codepoint(__s)\n",
        "__s = tokun.pipeline.decode(__s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeUxVkFq4CnA"
      },
      "outputs": [],
      "source": [
        "instruction_accuracy(y_true=__t, y_pred=__y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyQWEZkF7buC"
      },
      "outputs": [],
      "source": [
        "__yp = mlable.sampling.binary(__y, depth=8, threshold=0.6)\n",
        "__yp = mlable.shaping.merge(__yp, left_axis=-2, right_axis=-1, left=True)\n",
        "__op = revml.contract.pipeline.detokenize(__yp)\n",
        "__ip = [revml.contract.bytecode.iterate_over_instructions(bytes.fromhex(__h.decode('utf-8'))) for __h in __op.numpy().tolist()]\n",
        "__ip = ['|'.join(__i.hex() for __i in __c) for __c in __ip]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayUcuGW__Q01"
      },
      "outputs": [],
      "source": [
        "__yt = mlable.sampling.binary(__t, depth=8, threshold=0.6)\n",
        "__yt = mlable.shaping.merge(__yt, left_axis=-2, right_axis=-1, left=True)\n",
        "__ot = revml.contract.pipeline.detokenize(__yt)\n",
        "__it = [revml.contract.bytecode.iterate_over_instructions(bytes.fromhex(__h.decode('utf-8'))) for __h in __ot.numpy().tolist()]\n",
        "__it = ['|'.join(__i.hex() for __i in __c) for __c in __it]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(__it[0])\n",
        "print(__ip[0])"
      ],
      "metadata": {
        "id": "_uvkODzWhLm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_oyRgFE9ZR4"
      },
      "outputs": [],
      "source": [
        "print(__ot[1].numpy())\n",
        "print(__op[1].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-uKO2cFStt5"
      },
      "source": [
        "## Inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfopolmD9fNx"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGwvYHq4AJQ-"
      },
      "outputs": [],
      "source": [
        "# %tensorboard --logdir .logs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}