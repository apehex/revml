{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xXM7DoPpds1"
      },
      "source": [
        "## Import deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W24EKFXaO5yC"
      },
      "outputs": [],
      "source": [
        "!pip install -U datasets mlable tokun revml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXU-Ebl2pddk"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import functools\n",
        "import itertools\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import urllib.request\n",
        "\n",
        "import datasets as hd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import mlable.data\n",
        "import mlable.metrics\n",
        "import mlable.shaping\n",
        "\n",
        "import revml.contract.model\n",
        "import revml.contract.pipeline\n",
        "\n",
        "import tokun.data\n",
        "import tokun.evaluation\n",
        "import tokun.meta\n",
        "import tokun.model\n",
        "import tokun.pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pn1ywhSrpin9"
      },
      "outputs": [],
      "source": [
        "print(\"Tensorflow version \" + tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pQCOmISAQBu"
      },
      "source": [
        "## Setup the GPU / TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWMvVNSAJK_n"
      },
      "outputs": [],
      "source": [
        "# MIXED PRECISION #############################################################\n",
        "\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_bfloat16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFIMfPmgQa0h"
      },
      "outputs": [],
      "source": [
        "# DEVICES #####################################################################\n",
        "\n",
        "tf.debugging.set_log_device_placement(False)\n",
        "\n",
        "CPU = tf.config.list_logical_devices('CPU')\n",
        "GPU = tf.config.list_logical_devices('GPU')\n",
        "TPU = tf.config.list_logical_devices('TPU')\n",
        "\n",
        "if TPU:\n",
        "    RESOLVER = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(RESOLVER)\n",
        "    tf.tpu.experimental.initialize_tpu_system(RESOLVER)\n",
        "    DISTRIBUTION_STRATEGY = tf.distribute.TPUStrategy(RESOLVER)\n",
        "elif GPU:\n",
        "    DISTRIBUTION_STRATEGY = tf.distribute.MirroredStrategy(GPU)\n",
        "else:\n",
        "    DISTRIBUTION_STRATEGY = tf.distribute.MirroredStrategy(CPU)\n",
        "\n",
        "print(DISTRIBUTION_STRATEGY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9066X5EOyAX"
      },
      "source": [
        "## Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFSPMtQaO1fu"
      },
      "outputs": [],
      "source": [
        "# TOGGLE ######################################################################\n",
        "\n",
        "IMPORT = False\n",
        "DOWNLOAD = False\n",
        "TRAINING = True\n",
        "BINARY = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t1jfsJlM3SX"
      },
      "source": [
        "## Defining The Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAcVbS3_4jov"
      },
      "outputs": [],
      "source": [
        "# DATA PARAMETERS #############################################################\n",
        "\n",
        "BATCH_CONFIG = {\n",
        "    'batch_size': 64,\n",
        "    'drop_remainder': True,\n",
        "    'num_parallel_calls': tf.data.AUTOTUNE,}\n",
        "\n",
        "PIPELINE_CONFIG = {\n",
        "    'encoder': {\n",
        "        'batch_dim': BATCH_CONFIG['batch_size'],\n",
        "        'sample_dim': 512 * 8 * 33, # in bytes != codepoints\n",
        "        'input_dim': 8 * 33,\n",
        "        'sequence_axis': 1,\n",
        "        'feature_axis': -1,},\n",
        "    'decoder': {\n",
        "        'batch_dim': BATCH_CONFIG['batch_size'],\n",
        "        'sample_dim': 512 * 2 * 33,\n",
        "        'input_dim': 2 * 33,\n",
        "        'sequence_axis': 1,\n",
        "        'feature_axis': -1,\n",
        "        'data_weight': 1.0,\n",
        "        'padding_weight': 0.01,}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z74MlibMWnu"
      },
      "outputs": [],
      "source": [
        "# DECODER PARAMETERS ##########################################################\n",
        "\n",
        "DECODER_CONFIG = {\n",
        "  'num_layers': 8,\n",
        "  'num_heads': 16,\n",
        "  'input_dim': PIPELINE_CONFIG['decoder']['input_dim'],\n",
        "  'context_dim': PIPELINE_CONFIG['encoder']['input_dim'],\n",
        "  'embed_dim': 1056, # 4 * 33 * 8\n",
        "  'head_dim': 1056 // 16,\n",
        "  'hidden_dim': 1056 * 4,\n",
        "  'epsilon': 1e-6,}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm6y63XRBz07"
      },
      "outputs": [],
      "source": [
        "# DERIVED DECODING PARAMETERS #################################################\n",
        "\n",
        "DECODER_META = {\n",
        "    'version': '0.1',\n",
        "    'path': 'decoder.keras',\n",
        "    'url': '',}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21J7WEkhSwph"
      },
      "outputs": [],
      "source": [
        "# TRAINING PARAMETERS #########################################################\n",
        "\n",
        "OPTIMIZER_CONFIG = {\n",
        "    'learning_rate': 4 * 0.001 * (0.1 if IMPORT else 1.0),\n",
        "    'weight_decay': 0.1,\n",
        "    'beta_1': 0.9,\n",
        "    'beta_2': 0.95,\n",
        "    'clipnorm': 1.0,}\n",
        "\n",
        "SCHEDULER_CONFIG = {\n",
        "    'initial_learning_rate': OPTIMIZER_CONFIG['learning_rate'],\n",
        "    'decay_steps': 800 * 3,\n",
        "    'alpha': 0.1,\n",
        "    'name': 'cosine_lr',\n",
        "    'warmup_target': None,\n",
        "    'warmup_steps': 0,}\n",
        "\n",
        "METRICS_CONFIG = {\n",
        "    # 'factor': 256,\n",
        "    'depth': 8,}\n",
        "\n",
        "LOSS_CONFIG = {\n",
        "    'from_logits': False,\n",
        "    'label_smoothing': 0.,\n",
        "    'axis': -1,\n",
        "    'reduction': 'sum_over_batch_size',\n",
        "    'name': 'loss',}\n",
        "\n",
        "CHECKPOINT_CONFIG = {\n",
        "    'filepath': DECODER_META['path'],\n",
        "    'monitor': 'val_loss',\n",
        "    'mode': 'auto',\n",
        "    'save_freq': 'epoch',\n",
        "    'save_best_only': False,\n",
        "    'save_weights_only': False,\n",
        "    'verbose': 1,}\n",
        "\n",
        "TENSORBOARD_CONFIG = {\n",
        "    'log_dir': os.path.join('.logs/', *DECODER_META['version'], datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")),\n",
        "    'histogram_freq': 1,\n",
        "    'embeddings_freq': 0,\n",
        "    'profile_batch': (128, 256),\n",
        "    'write_graph': False,\n",
        "    'write_images': True,}\n",
        "\n",
        "TRAINING_CONFIG = {\n",
        "    'epochs': 8,\n",
        "    'batch_size': None,\n",
        "    'validation_split': None,\n",
        "    'validation_freq': list(range(1, 9)),\n",
        "    # 'class_weight': {__c: 0.03 if __c == 0 else 1. for __c in range(PIPELINE_CONFIG['decoder']['input_dim'])}, # there are 32 times more 0s than other bytes (most instructions have null data)\n",
        "    'verbose': 1,}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zjz1sxOju7jM"
      },
      "source": [
        "## Download The Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfIZb86Fg0dQ"
      },
      "outputs": [],
      "source": [
        "# DECODER #####################################################################\n",
        "\n",
        "if IMPORT and DOWNLOAD:\n",
        "    urllib.request.urlretrieve(DECODER_META['url'], DECODER_META['path'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEyFtkcFNGe4"
      },
      "source": [
        "## Loading The Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukG8ql_qxOl_"
      },
      "outputs": [],
      "source": [
        "# EVMC DATASET ################################################################\n",
        "\n",
        "EVMC_TRAIN = hd.load_dataset('apehex/evm_contracts', name='hex-ethereum', split='cleaned[:90%]').to_tf_dataset(shuffle=True, batch_size=None)\n",
        "EVMC_TEST = hd.load_dataset('apehex/evm_contracts', name='hex-ethereum', split='cleaned[90%:]').to_tf_dataset(shuffle=True, batch_size=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cheN52OEchs"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJMB7pPdCcnA"
      },
      "outputs": [],
      "source": [
        "# EVMC ########################################################################\n",
        "\n",
        "# specialized preprocessing fn\n",
        "__preprocess = revml.contract.pipeline.preprocess_factory(\n",
        "    decoder_config=PIPELINE_CONFIG['decoder'],\n",
        "    encoder_config=PIPELINE_CONFIG['encoder'],)\n",
        "\n",
        "# apply\n",
        "with DISTRIBUTION_STRATEGY.scope():\n",
        "    EVMC_TRAIN = EVMC_TRAIN.batch(**BATCH_CONFIG).map(__preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    EVMC_TEST = EVMC_TEST.batch(**BATCH_CONFIG).map(__preprocess, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ3quJQ4EUKf"
      },
      "outputs": [],
      "source": [
        "# INSPECT #####################################################################\n",
        "\n",
        "(__X, __C), __T, __W = next(iter(EVMC_TEST.take(1)))\n",
        "\n",
        "print(EVMC_TRAIN.element_spec)\n",
        "print(EVMC_TEST.element_spec)\n",
        "\n",
        "print('evmc train: {:,}'.format(EVMC_TRAIN.cardinality().numpy()))\n",
        "print('evmc test:  {:,}'.format(EVMC_TEST.cardinality().numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbkaXey44V5Q"
      },
      "source": [
        "## Init The Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP_Jj3JYY3yb"
      },
      "outputs": [],
      "source": [
        "# DEBUG #######################################################################\n",
        "\n",
        "class DebugModel(tf.keras.models.Model):\n",
        "    def __init__(self, output_dim: int, **kwargs) -> None:\n",
        "        # init\n",
        "        super(DebugModel, self).__init__(**kwargs)\n",
        "        # layers\n",
        "        self._head = tf.keras.layers.Dense(units=output_dim, activation='sigmoid', use_bias=False, kernel_initializer='glorot_uniform', bias_initializer='zeros', name='head')\n",
        "\n",
        "    def call(self, inputs: tuple, **kwargs) -> tf.Tensor:\n",
        "        return self._head(inputs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqJLSg1atBo7"
      },
      "outputs": [],
      "source": [
        "# METRICS #####################################################################\n",
        "\n",
        "_Accuracy = mlable.metrics.BinaryGroupAccuracy if BINARY else mlable.metrics.RawGroupAccuracy\n",
        "_Loss = tf.keras.losses.BinaryCrossentropy if BINARY else tf.keras.losses.MeanSquaredError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEpY1-vFIFX7"
      },
      "outputs": [],
      "source": [
        "# COMPILE #####################################################################\n",
        "\n",
        "with DISTRIBUTION_STRATEGY.scope():\n",
        "    # COSINE LR ###############################################################\n",
        "    cosine_lr = tf.keras.optimizers.schedules.CosineDecay(**SCHEDULER_CONFIG)\n",
        "    OPTIMIZER_CONFIG['learning_rate'] = cosine_lr\n",
        "    # metrics\n",
        "    byte_accuracy = _Accuracy(group=1, name='byte_accuracy', **METRICS_CONFIG)\n",
        "    instruction_accuracy = _Accuracy(group=33, name='instruction_accuracy', **METRICS_CONFIG)\n",
        "    token_accuracy = _Accuracy(group=DECODER_CONFIG['input_dim'], name='token_accuracy', **METRICS_CONFIG)\n",
        "    # decoder\n",
        "    DECODER = revml.contract.model.Transformer(**DECODER_CONFIG)\n",
        "    if IMPORT and os.path.isfile(DECODER_META['path']): DECODER = tf.keras.models.load_model(DECODER_META['path'], compile=False)\n",
        "    # build\n",
        "    DECODER((__X, __C))\n",
        "    # compile\n",
        "    DECODER.compile(\n",
        "        optimizer=tf.keras.optimizers.AdamW(**OPTIMIZER_CONFIG),\n",
        "        loss=_Loss(**LOSS_CONFIG),\n",
        "        weighted_metrics=[byte_accuracy, instruction_accuracy, token_accuracy])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuRwWdjpPQBM"
      },
      "outputs": [],
      "source": [
        "DECODER.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRkNkXthBwar"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beTpALmzFdu1"
      },
      "outputs": [],
      "source": [
        "# TRAIN #######################################################################\n",
        "\n",
        "if TRAINING:\n",
        "    with DISTRIBUTION_STRATEGY.scope():\n",
        "        # callbacks\n",
        "        cp_callback = tf.keras.callbacks.ModelCheckpoint(**CHECKPOINT_CONFIG)\n",
        "        tb_callback = tf.keras.callbacks.TensorBoard(**TENSORBOARD_CONFIG)\n",
        "        # fit model\n",
        "        TRAINING_HISTORY = DECODER.fit(\n",
        "            x=EVMC_TRAIN.prefetch(tf.data.AUTOTUNE),\n",
        "            validation_data=EVMC_TEST.prefetch(tf.data.AUTOTUNE),\n",
        "            callbacks=[cp_callback, tb_callback],\n",
        "            **TRAINING_CONFIG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHtROW1K1R7c"
      },
      "source": [
        "## Dataviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiRVgG-oSfb7"
      },
      "outputs": [],
      "source": [
        "# DATA ########################################################################\n",
        "\n",
        "__i = iter(EVMC_TEST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DBwlFAb--Ah"
      },
      "outputs": [],
      "source": [
        "(__x, __c), __t, __w = next(__i)\n",
        "__y = DECODER((__x, __c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGuCvlVGN1wg"
      },
      "outputs": [],
      "source": [
        "__s = tf.reshape(__c, (BATCH_CONFIG['batch_size'], -1))\n",
        "__s = tokun.pipeline.codepoint(__s)\n",
        "__s = tokun.pipeline.decode(__s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeUxVkFq4CnA"
      },
      "outputs": [],
      "source": [
        "instruction_accuracy(y_true=__t, y_pred=__y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyQWEZkF7buC"
      },
      "outputs": [],
      "source": [
        "__yp = mlable.sampling.binary(__y, depth=8, threshold=0.6)\n",
        "__yp = mlable.shaping.merge(__yp, left_axis=-2, right_axis=-1, left=True)\n",
        "__op = revml.contract.pipeline.detokenize(__yp)\n",
        "__ip = [revml.contract.bytecode.iterate_over_instructions(bytes.fromhex(__h.decode('utf-8'))) for __h in __op.numpy().tolist()]\n",
        "__ip = ['|'.join(__i.hex() for __i in __c) for __c in __ip]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayUcuGW__Q01"
      },
      "outputs": [],
      "source": [
        "__yt = mlable.sampling.binary(__t, depth=8, threshold=0.6)\n",
        "__yt = mlable.shaping.merge(__yt, left_axis=-2, right_axis=-1, left=True)\n",
        "__ot = revml.contract.pipeline.detokenize(__yt)\n",
        "__it = [revml.contract.bytecode.iterate_over_instructions(bytes.fromhex(__h.decode('utf-8'))) for __h in __ot.numpy().tolist()]\n",
        "__it = ['|'.join(__i.hex() for __i in __c) for __c in __it]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(__it[0])\n",
        "print(__ip[0])"
      ],
      "metadata": {
        "id": "_uvkODzWhLm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_oyRgFE9ZR4"
      },
      "outputs": [],
      "source": [
        "print(__ot[1].numpy())\n",
        "print(__op[1].numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-uKO2cFStt5"
      },
      "source": [
        "## Inspect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfopolmD9fNx"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGwvYHq4AJQ-"
      },
      "outputs": [],
      "source": [
        "# %tensorboard --logdir .logs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}